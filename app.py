import pandas as pd
import plotly.express as px
import streamlit as st
import requests
import torch
import sys
import os
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from math import radians, sin, cos, sqrt, atan2
from datetime import datetime, timedelta

# ƒê·∫∑t c·∫•u h√¨nh trang ngay ƒë·∫ßu script
st.set_page_config(page_title="Air Quality Dashboard", layout="wide")

# Th√™m CSS cho recommendation-box
st.markdown(
    """
    <style>
    .recommendation-box {
        background-color: #f0f0f0;
        padding: 10px;
        border-radius: 5px;
        margin-top: 10px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Th√™m th∆∞ m·ª•c SOFTS v√†o sys.path (thay ƒë∆∞·ªùng d·∫´n n√†y b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø tr√™n m√°y c·ªßa b·∫°n)
SOFTS_PATH = r"C:\Users\NITRO\Desktop\Workspace\CS313\AQI-Globe\SOFTS"
sys.path.append(SOFTS_PATH)

# Ki·ªÉm tra xem c√≥ th·ªÉ import Exp_Custom kh√¥ng
try:
    from exp.exp_custom import Exp_Custom
except ModuleNotFoundError as e:
    st.error(f"Kh√¥ng th·ªÉ import Exp_Custom. H√£y ƒë·∫£m b·∫£o th∆∞ m·ª•c 'SOFTS' t·ªìn t·∫°i t·∫°i {SOFTS_PATH} v√† ch·ª©a 'exp/exp_custom.py'. L·ªói: {e}")
    st.stop()

# ƒê·ªãnh nghƒ©a c√°c l·ªõp m√¥ h√¨nh
class STAR(nn.Module):
    def __init__(self, d_series, d_core):
        super(STAR, self).__init__()
        self.gen1 = nn.Linear(d_series, d_series)
        self.gen2 = nn.Linear(d_series, d_core)
        self.gen3 = nn.Linear(d_series + d_core, d_series)
        self.gen4 = nn.Linear(d_series, d_series)

    def forward(self, input, *args, **kwargs):
        batch_size, channels, d_series = input.shape
        combined_mean = F.gelu(self.gen1(input))
        combined_mean = self.gen2(combined_mean)
        weight = F.softmax(combined_mean, dim=1)
        combined_mean = torch.sum(combined_mean * weight, dim=1, keepdim=True).repeat(1, channels, 1)
        combined_mean_cat = torch.cat([input, combined_mean], -1)
        combined_mean_cat = F.gelu(self.gen3(combined_mean_cat))
        combined_mean_cat = self.gen4(combined_mean_cat)
        return combined_mean_cat, None

class DataEmbedding_inverted(nn.Module):
    def __init__(self, seq_len, d_model, dropout=0.05):
        super(DataEmbedding_inverted, self).__init__()
        self.value_embedding = nn.Linear(seq_len, d_model)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x, x_mark=None):
        x = x.permute(0, 2, 1)
        x = self.value_embedding(x)
        x = x.permute(0, 2, 1)
        x = self.dropout(x)
        return x

class EncoderLayer(nn.Module):
    def __init__(self, attention, d_model, d_ff=512, dropout=0.05, activation="gelu"):
        super(EncoderLayer, self).__init__()
        self.attention = attention
        self.conv1 = nn.Conv1d(d_model, d_ff, kernel_size=1)
        self.conv2 = nn.Conv1d(d_ff, d_model, kernel_size=1)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)
        self.activation = F.gelu if activation == "gelu" else F.relu

    def forward(self, x, attn_mask=None):
        new_x, _ = self.attention(x)
        x = x + self.dropout(new_x)
        x = self.norm1(x)
        x = x.permute(0, 2, 1)
        y = self.conv1(x)
        y = self.activation(y)
        y = self.conv2(y)
        y = y.permute(0, 2, 1)
        y = self.norm2(x.permute(0, 2, 1) + self.dropout(y))
        return y, None

class Encoder(nn.Module):
    def __init__(self, attn_layers):
        super(Encoder, self).__init__()
        self.attn_layers = nn.ModuleList(attn_layers)

    def forward(self, x, attn_mask=None):
        attns = []
        for attn_layer in self.attn_layers:
            x, attn = attn_layer(x, attn_mask)
            attns.append(attn)
        return x, attns

class Model(nn.Module):
    def __init__(self, configs):
        super(Model, self).__init__()
        self.seq_len = configs.seq_len
        self.pred_len = configs.pred_len
        self.enc_embedding = DataEmbedding_inverted(configs.seq_len, configs.d_model, configs.dropout)
        self.use_norm = configs.use_norm
        self.encoder = Encoder(
            [
                EncoderLayer(
                    STAR(configs.d_model, configs.d_core),
                    configs.d_model,
                    configs.d_ff,
                    dropout=configs.dropout,
                    activation=configs.activation,
                ) for l in range(configs.e_layers)
            ]
        )
        self.projection = nn.Linear(configs.d_model, configs.pred_len, bias=True)

    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):
        if self.use_norm:
            means = x_enc.mean(1, keepdim=True).detach()
            x_enc = x_enc - means
            stdev = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)
            x_enc /= stdev
        _, _, N = x_enc.shape
        enc_out = self.enc_embedding(x_enc, x_mark_enc)
        enc_out, attns = self.encoder(enc_out, attn_mask=None)
        dec_out = self.projection(enc_out).permute(0, 2, 1)[:, :, :N]
        if self.use_norm:
            dec_out = dec_out * (stdev[:, 0, :].unsqueeze(1).repeat(1, self.pred_len, 1))
            dec_out = dec_out + (means[:, 0, :].unsqueeze(1).repeat(1, self.pred_len, 1))
        return dec_out

    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):
        dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)
        return dec_out[:, -self.pred_len:, :]

# H√†m ph√¢n lo·∫°i AQI v√† tr·∫£ v·ªÅ khuy·∫øn ngh·ªã 
def classify_aqi(value):
    if value <= 50:
        return {
            "advice": "Kh√¥ng kh√≠ trong l√†nh. B·∫°n c√≥ th·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi b√¨nh th∆∞·ªùng."
        }
    elif value <= 100:
        return {
            "advice": "Ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ c√≥ th·ªÉ ch·∫•p nh·∫≠n ƒë∆∞·ª£c tuy nhi√™n, ƒë·ªëi v·ªõi ng∆∞·ªùi c√≥ da nh·∫°y c·∫£m n√™n h·∫°n ch·∫ø ra ngo√†i trong th·ªùi gian d√†i."
        }
    elif value <= 150:
        return {
            "advice": "Ng∆∞·ªùi c√≥ b·ªánh h√¥ h·∫•p, ng∆∞·ªùi gi√†, tr·∫ª nh·ªè n√™n h·∫°n ch·∫ø ho·∫°t ƒë·ªông ngo√†i tr·ªùi trong th·ªùi gian d√†i."
        }
    elif value <= 200:
        return {
            "advice": "B·∫°n n√™n h·∫°n ch·∫ø ho·∫°t ƒë·ªông ngo√†i tr·ªùi. ƒê·ªëi v·ªõi nh·ªØng ng∆∞·ªùi c√≥ da nh·∫°y c·∫£m n√™n ·ªü trong nh√† trong th·ªùi gian n√†y."
        }
    elif value <= 300:
        return {
            "advice": "B·∫°n n√™n h·∫°n ch·∫ø t·ªëi ƒëa c√°c ho·∫°t ƒë·ªông ngo√†i tr·ªùi. ƒê·ªëi v·ªõi nh√≥m ng∆∞·ªùi c√≥ da nh·∫°y c·∫£m n√™n tr√°nh ra ngo√†i ho√†n to√†n."
        }
    else:
        return {
            "advice": "T√¨nh tr·∫°ng √¥ nhi·ªÖm nghi√™m tr·ªçng, b·∫°n n√™n ·ªü trong nh√†. N·∫øu ra ngo√†i trong th·ªùi gian d√†i c√≥ th·ªÉ g√¢y nguy hi·ªÉm ƒë·∫øn t√≠nh m·∫°ng."
        }

# H√†m t√≠nh kho·∫£ng c√°ch Haversine gi·ªØa hai ƒëi·ªÉm (ƒë∆°n v·ªã: km)
def haversine_distance(lat1, lon1, lat2, lon2):
    R = 6371  # B√°n k√≠nh Tr√°i ƒê·∫•t (km)
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c

# H√†m t√≠nh AQI cho t·ª´ng ch·∫•t g√¢y √¥ nhi·ªÖm (theo chu·∫©n VN_AQI)
def calculate_pollutant_aqi(pollutant, value):
    # Ng∆∞·ª°ng d·ª±a tr√™n VN_AQI (tham kh·∫£o t·ª´ t√†i li·ªáu, ƒëi·ªÅu ch·ªânh cho ph√π h·ª£p)
    ranges = {
        'pm25': [
            (0, 12.0, 0, 50),    # T·ªët
            (12.1, 35.4, 51, 100),  # Trung b√¨nh
            (35.5, 55.4, 101, 150),  # K√©m
            (55.5, 150.4, 151, 200),  # X·∫•u
            (150.5, 250.4, 201, 300),  # R·∫•t x·∫•u
            (250.5, 500.4, 301, 500)  # Nguy h·∫°i
        ],
        'pm10': [
            (0, 54, 0, 50),
            (55, 154, 51, 100),
            (155, 254, 101, 150),
            (255, 354, 151, 200),
            (355, 424, 201, 300),
            (425, 604, 301, 500)
        ],
        'no2': [  # ¬µg/m¬≥
            (0, 40, 0, 50),
            (41, 80, 51, 100),
            (81, 180, 101, 150),
            (181, 280, 151, 200),
            (281, 400, 201, 300),
            (401, 750, 301, 500)
        ],
        'co': [  # mg/m¬≥
            (0, 4.4, 0, 50),
            (4.5, 9.4, 51, 100),
            (9.5, 12.4, 101, 150),
            (12.5, 15.4, 151, 200),
            (15.5, 30.4, 201, 300),
            (30.5, 50.4, 301, 500)
        ],
        'o3': [  # ¬µg/m¬≥ (8 gi·ªù trung b√¨nh)
            (0, 50, 0, 50),
            (51, 100, 51, 100),
            (101, 140, 101, 150),
            (141, 200, 151, 200),
            (201, 300, 201, 300),
            (301, 500, 301, 500)
        ]
    }
    pollutant_ranges = ranges.get(pollutant, [(0, 500, 0, 500)])
    if pd.isna(value) or value is None:
        return 0  # M·∫∑c ƒë·ªãnh AQI = 0 n·∫øu thi·∫øu d·ªØ li·ªáu
    for c_low, c_high, i_low, i_high in pollutant_ranges:
        if c_low <= value <= c_high:
            return round(((i_high - i_low) / (c_high - c_low)) * (value - c_low) + i_low)
    return 0

# H√†m t√≠nh AQI t·ªïng qu√°t
def calculate_aqi(pollutants):
    aqi_values = []
    for pollutant, value in pollutants.items():
        if pd.notna(value) and value is not None and value > 0:
            aqi = calculate_pollutant_aqi(pollutant, value)
            aqi_values.append(aqi)
    return max(aqi_values) if aqi_values else 0

# H√†m nh√≥m c√°c tr·∫°m v√† chia s·∫ª ch·ªâ s·ªë
def share_pollutants(data, distance_threshold=50):
    pollutants = data['parameter'].dropna().unique()
    pollutants = [p for p in pollutants if p in ['pm25', 'pm10', 'no2', 'co', 'o3']]
    
    stations = data[['location_id', 'lat', 'lng']].drop_duplicates()
    
    groups = []
    used = set()
    for i, station in stations.iterrows():
        if station['location_id'] in used:
            continue
        group = [station['location_id']]
        used.add(station['location_id'])
        for j, other_station in stations.iterrows():
            if other_station['location_id'] in used or other_station['location_id'] == station['location_id']:
                continue
            dist = haversine_distance(station['lat'], station['lng'], other_station['lat'], other_station['lng'])
            if dist <= distance_threshold:
                group.append(other_station['location_id'])
                used.add(other_station['location_id'])
        groups.append(group)
    
    latest_data = data.sort_values('time_index').groupby(['location_id', 'parameter'])['value'].last().unstack().reset_index()
    
    updated_data = data.copy()
    for group in groups:
        group_data = latest_data[latest_data['location_id'].isin(group)]
        for pollutant in pollutants:
            if pollutant not in group_data.columns:
                continue
            missing_stations = group_data['location_id'][group_data[pollutant].isna()]
            if not missing_stations.empty:
                valid_values = group_data[pollutant].dropna()
                if not valid_values.empty:
                    mean_value = valid_values.mean()
                    for station in missing_stations:
                        mask = (updated_data['location_id'] == station) & (updated_data['parameter'] == pollutant)
                        latest_time = updated_data[mask]['time_index'].max() if mask.any() else None
                        if pd.notna(latest_time):
                            if not mask.any():
                                new_row = updated_data[updated_data['location_id'] == station].iloc[0].copy()
                                new_row['parameter'] = pollutant
                                new_row['value'] = mean_value
                                new_row['time_index'] = latest_time
                                updated_data = pd.concat([updated_data, pd.DataFrame([new_row])], ignore_index=True)
                            else:
                                updated_data.loc[mask & (updated_data['time_index'] == latest_time), 'value'] = mean_value
    
    return updated_data

# H√†m t·∫£i m√¥ h√¨nh
def load_model(model_path=r"C:\Users\NITRO\Desktop\Workspace\CS313\AQI-Globe\softs.pt"):
    import argparse
    config = {
        'root_path': './',
        'data_path': '/kaggle/input/openaq-26-sensors/merged_openaq_2024_2025_timeseries_cleaned.csv',
        'data': 'air_pm25',
        'features': 'M',
        'freq': 'h',
        'seq_len': 336,
        'pred_len': 24,
        'model': 'SOFTS',
        'checkpoints': './checkpoints/',
        'd_model': 256,
        'd_core': 128,
        'd_ff': 512,
        'e_layers': 4,
        'learning_rate': 0.00005,
        'lradj': 'cosine',
        'train_epochs': 100,
        'patience': 10,
        'batch_size': 8,
        'dropout': 0.05,
        'activation': 'gelu',
        'use_norm': True,
        'num_workers': 0,
        'use_gpu': True,
        'gpu': '0',
        'save_model': True,
    }
    parser = argparse.ArgumentParser()
    args = parser.parse_args([])
    args.__dict__.update(config)
    args.use_gpu = torch.cuda.is_available() and args.use_gpu
    try:
        exp = Exp_Custom(args)
        exp.model.load_state_dict(torch.load(model_path, map_location='cpu'))
        exp.model.eval()
        return exp
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
        return None

# H√†m d·ª± ƒëo√°n cho t·∫•t c·∫£ c√°c ch·ªâ s·ªë
def predict_pollutants(exp, data, location_id, hours_ahead, pollutants=['pm25', 'pm10', 'no2', 'co', 'o3']):
    predictions = {}
    for pollutant in pollutants:
        pollutant_data = data[(data['location_id'] == location_id) & (data['parameter'] == pollutant)]
        if pollutant_data.empty or len(pollutant_data) < 336:
            predictions[pollutant] = 0  # ƒê·∫∑t m·∫∑c ƒë·ªãnh l√† 0 n·∫øu thi·∫øu d·ªØ li·ªáu
            continue
        
        pollutant_data = pollutant_data.sort_values('time_index', ascending=True)
        input_data = pollutant_data['value'].tail(336).values
        
        input_tensor = torch.tensor(input_data, dtype=torch.float32).reshape(1, 336, 1)
        x_mark_enc = torch.zeros(1, 336, 1)
        
        try:
            with torch.no_grad():
                output = exp.model(input_tensor, x_mark_enc, None, None)
                if hours_ahead <= 24:
                    predicted_value = output[0, min(hours_ahead - 1, 23), 0].item()
                    predictions[pollutant] = predicted_value
                else:
                    predicted_values = output[0, :, 0].numpy().tolist()
                    predictions[pollutant] = predicted_values[0]  # L·∫•y gi√° tr·ªã ƒë·∫ßu ti√™n
        except Exception as e:
            predictions[pollutant] = 0  # ƒê·∫∑t m·∫∑c ƒë·ªãnh l√† 0 n·∫øu x·∫£y ra l·ªói
    
    return predictions

# H√†m d·ª± ƒëo√°n AQI cho 24 gi·ªù ti·∫øp theo t·ª´ th·ªùi gian hi·ªán t·∫°i
def predict_daily_aqi(exp, data, location_id, current_time, pollutants=['pm25', 'pm10', 'no2', 'co', 'o3']):
    daily_predictions = []
    # T√≠nh s·ªë gi·ªù c√≤n l·∫°i ƒë·∫øn 07:00 AM ng√†y h√¥m sau
    end_time = current_time.replace(hour=7, minute=0, second=0, microsecond=0) + timedelta(days=1)
    if current_time.hour >= 7:
        end_time += timedelta(days=1)
    hours_to_end = int((end_time - current_time).total_seconds() / 3600)

    # D·ª± ƒëo√°n AQI cho t·ª´ng gi·ªù t·ª´ hi·ªán t·∫°i ƒë·∫øn 07:00 AM ng√†y h√¥m sau
    for hour in range(1, hours_to_end + 1):
        predictions = predict_pollutants(exp, data, location_id, hour)
        latest_pollutants = {p: predictions.get(p, 0) for p in pollutants}
        aqi = calculate_aqi(latest_pollutants)
        daily_predictions.append(aqi)
    
    return daily_predictions

# H√†m t√¨m kho·∫£ng th·ªùi gian t·ªët nh·∫•t (AQI ‚â§ 100: T·ªët v√† Trung b√¨nh)
def find_best_time_slots(aqi_values, current_time):
    if not aqi_values:
        return None, None, False, False
    best_slots = []
    start = None
    
    for i, aqi in enumerate(aqi_values):
        if aqi <= 100 and start is None:
            start = i
        elif aqi > 100 and start is not None:
            end = i - 1
            best_slots.append((start, end, end - start + 1))
            start = None
    if start is not None:
        end = len(aqi_values) - 1
        best_slots.append((start, end, end - start + 1))
    
    if not best_slots:
        return None, None, False, False
    
    # Ch·ªçn kho·∫£ng th·ªùi gian d√†i nh·∫•t ho·∫∑c s·ªõm nh·∫•t n·∫øu c√≥ nhi·ªÅu kho·∫£ng b·∫±ng nhau
    best_slot = max(best_slots, key=lambda x: (x[2], -x[0]))  # ∆Øu ti√™n ƒë·ªô d√†i, r·ªìi ∆∞u ti√™n gi·ªù s·ªõm
    start_hour = (current_time + timedelta(hours=best_slot[0] + 1)).hour
    end_hour = (current_time + timedelta(hours=best_slot[1] + 1)).hour
    
    # X√°c ƒë·ªãnh ng√†y c·ªßa start v√† end
    start_date = (current_time + timedelta(hours=best_slot[0] + 1)).date()
    end_date = (current_time + timedelta(hours=best_slot[1] + 1)).date()
    current_date = current_time.date()
    
    return start_hour, end_hour, start_date == current_date, end_date == current_date

# H√†m l·∫•y d·ªØ li·ªáu t·ª´ API
def fetch_data_from_api():
    try:
        response = requests.get("http://localhost:8000/data")
        response.raise_for_status()
        data = response.json()
        df = pd.DataFrame(data)
        return df
    except requests.RequestException as e:
        st.error(f"L·ªói khi l·∫•y d·ªØ li·ªáu t·ª´ API: {e}")
        return pd.DataFrame()

# L·∫•y d·ªØ li·ªáu
final = fetch_data_from_api()

# Ki·ªÉm tra xem d·ªØ li·ªáu c√≥ r·ªóng kh√¥ng
if final.empty:
    st.error("Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra API.")
    st.stop()

# ƒê·∫£m b·∫£o location_id l√† ki·ªÉu int
final['location_id'] = final['location_id'].astype(int)

# Chia s·∫ª ch·ªâ s·ªë gi·ªØa c√°c tr·∫°m g·∫ßn nhau
final = share_pollutants(final, distance_threshold=50)

# H√†m t√≠nh AQI v√† ph√¢n lo·∫°i
def get_aqi_category(aqi):
    if aqi <= 50:
        return "T·ªët"
    elif aqi <= 100:
        return "Trung b√¨nh"
    elif aqi <= 150:
        return "K√©m"
    elif aqi <= 200:
        return "X·∫•u"
    elif aqi <= 300:
        return "R·∫•t x·∫•u"
    else:
        return "Nguy h·∫°i"

# T√≠nh AQI cho t·ª´ng ƒë·ªãa ƒëi·ªÉm
pollutants = final['parameter'].dropna().unique()
pollutants = [p for p in pollutants if p in ['pm25', 'pm10', 'no2', 'co', 'o3']]
latest_data = final.sort_values('time_index').groupby(['location_id', 'location_name', 'Country', 'lat', 'lng', 'parameter'])['value'].last().unstack().reset_index()
latest_data['aqi'] = latest_data.apply(
    lambda row: calculate_aqi({p: row[p] for p in pollutants if p in row and pd.notna(row[p])}), axis=1
)
latest_data['category'] = latest_data['aqi'].apply(get_aqi_category)

# Th√™m c·ªôt aqi_text ƒë·ªÉ hi·ªÉn th·ªã gi√° tr·ªã AQI tr√™n b·∫£n ƒë·ªì
latest_data['aqi_text'] = latest_data['aqi'].astype(str)

# T·∫°o c·ªôt size ƒë·ªÉ l√†m n·ªïi b·∫≠t location ƒë∆∞·ª£c ch·ªçn
latest_data['size'] = 10

# ƒê·ªãnh nghƒ©a thang m√†u AQI ƒë·∫ßy ƒë·ªß
aqi_colors = {
    "T·ªët": "green",
    "Trung b√¨nh": "yellow",
    "K√©m": "orange",
    "X·∫•u": "red",
    "R·∫•t x·∫•u": "purple",
    "Nguy h·∫°i": "maroon"
}

# Th·ªùi gian hi·ªán t·∫°i
current_time = datetime.now()  # L·∫•y th·ªùi gian h·ªá th·ªëng

st.title("üåç Air Quality Monitoring Dashboard")

# Hi·ªÉn th·ªã c√°c tab (Ranking, Map, Predict) c√πng h√†ng
col1, col2, col3 = st.columns([1, 2, 1])

with col1:
    st.subheader(" X·∫øp h·∫°ng tr·ª±c ti·∫øp ƒë·ªãa ƒëi·ªÉm s·∫°ch nh·∫•t theo th·ªùi gian th·ª±c")
    # T·∫°o b·∫£ng x·∫øp h·∫°ng v·ªõi c·ªôt Th·ª© h·∫°ng v√† ƒê·ªãa ƒëi·ªÉm
    ranking_data = latest_data[['location_name', 'aqi']].sort_values('aqi')
    # Th√™m c·ªôt Th·ª© h·∫°ng (Rank) t·ª´ 1 tr·ªü l√™n
    ranking_data['Th·ª© h·∫°ng'] = range(1, len(ranking_data) + 1)
    # S·∫Øp x·∫øp l·∫°i c·ªôt ƒë·ªÉ Th·ª© h·∫°ng n·∫±m tr∆∞·ªõc ƒê·ªãa ƒëi·ªÉm
    ranking_data = ranking_data[['Th·ª© h·∫°ng', 'location_name']].rename(columns={'location_name': 'ƒê·ªãa ƒëi·ªÉm'})
    # Reset index v√† lo·∫°i b·ªè c·ªôt index
    ranking_data = ranking_data.reset_index(drop=True)
    # S·ª≠ d·ª•ng st.table() ho·∫∑c st.dataframe() v·ªõi hide_index
    st.dataframe(ranking_data, hide_index=True, use_container_width=True)

with col2:
    st.subheader("üó∫Ô∏è B·∫£n ƒë·ªì ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠ (AQI)")
    # Dropdown ƒë·ªÉ ch·ªçn location l√†m n·ªïi b·∫≠t tr√™n b·∫£n ƒë·ªì
    unique_locations = latest_data['location_name'].unique()
    highlight_location = st.selectbox('Ch·ªçn ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ l√†m n·ªïi b·∫≠t tr√™n b·∫£n ƒë·ªì:', ['T·∫•t c·∫£'] + list(unique_locations))

    if highlight_location != 'T·∫•t c·∫£':
        latest_data.loc[latest_data['location_name'] == highlight_location, 'size'] = 80

    # ƒê·∫£m b·∫£o hi·ªÉn th·ªã to√†n b·ªô thang ƒëo AQI trong legend
    fig_map = px.scatter_mapbox(
        latest_data,
        lat='lat',
        lon='lng',
        size='size',
        color='category',
        color_discrete_map=aqi_colors,
        category_orders={"category": ["T·ªët", "Trung b√¨nh", "K√©m", "X·∫•u", "R·∫•t x·∫•u", "Nguy h·∫°i"]},
        text='aqi_text',  # Hi·ªÉn th·ªã gi√° tr·ªã AQI tr√™n marker
        hover_name='location_name',
        hover_data={'category': True, 'aqi': True, 'lat': False, 'lng': False, 'size': False},
        mapbox_style='carto-positron',
        zoom=2,
        title="AQI Across Locations"
    )
    fig_map.update_traces(
        textposition='middle center',  # ƒê·∫∑t v·ªã tr√≠ text ·ªü gi·ªØa marker
        textfont=dict(size=12, color='black'),  # T√πy ch·ªânh font ch·ªØ c·ªßa AQI
        marker=dict(sizemin=10)  # ƒê·∫£m b·∫£o marker ƒë·ªß l·ªõn ƒë·ªÉ hi·ªÉn th·ªã text
    )
    fig_map.update_layout(
        legend_title_text='AQI',
        legend=dict(
            title="M·ª©c AQI",
            itemsizing='constant',
            orientation='v',
            yanchor='top',
            y=1,
            xanchor='right',
            x=1
        )
    )
    st.plotly_chart(fig_map, use_container_width=True)

with col3:
    st.subheader("D·ª± ƒëo√°n")
    # T·∫°o tab cho AQI v√† S·ª©c kh·ªèe
    tab1, tab2 = st.tabs(["AQI", "S·ª©c kh·ªèe"])

    # Tab AQI
    with tab1:
        st.subheader("üå´Ô∏è D·ª± ƒëo√°n AQI")
        if highlight_location != 'T·∫•t c·∫£':
            location_id = latest_data[latest_data['location_name'] == highlight_location]['location_id'].iloc[0]
            current_aqi = latest_data[latest_data['location_name'] == highlight_location]['aqi'].iloc[0]

            # T·∫£i m√¥ h√¨nh
            exp = load_model(r"C:\Users\NITRO\Desktop\Workspace\CS313\AQI-Globe\softs.pt")

            # Hi·ªÉn th·ªã AQI hi·ªán t·∫°i
            if current_aqi is not None and pd.notna(current_aqi):
                st.write(f"**AQI Hi·ªán t·∫°i**: {current_aqi}")
                classification = classify_aqi(current_aqi)
                st.markdown(
                    f"""
                    <div class="recommendation-box">
                        {classification['advice']}
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                # Th√™m khuy·∫øn ngh·ªã gi·ªù ho·∫°t ƒë·ªông
                if exp is not None:
                    daily_aqi = predict_daily_aqi(exp, final, location_id, current_time)
                    if daily_aqi and all(aqi <= 100 for aqi in daily_aqi):
                        st.markdown(
                            f"""
                            <div class="recommendation-box">
                                B·∫°n c√≥ th·ªÉ t·∫≠n h∆∞·ªüng c·∫£ ng√†y h√¥m nay ·ªü ngo√†i tr·ªùi.
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
                    else:
                        start_hour, end_hour, start_is_today, end_is_today = find_best_time_slots(daily_aqi, current_time)
                        if start_hour is not None and end_hour is not None:
                            if start_hour == end_hour:
                                if start_is_today:
                                    st.markdown(
                                        f"""
                                        <div class="recommendation-box">
                                            Th·ªùi ƒëi·ªÉm t·ªët nh·∫•t ƒë·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi: {start_hour:02d}h h√¥m nay.
                                        </div>
                                        """,
                                        unsafe_allow_html=True
                                    )
                                else:
                                    st.markdown(
                                        f"""
                                        <div class="recommendation-box">
                                            Th·ªùi ƒëi·ªÉm t·ªët nh·∫•t ƒë·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi: {start_hour:02d}h ng√†y mai.
                                        </div>
                                        """,
                                        unsafe_allow_html=True
                                    )
                            elif start_is_today and end_is_today:
                                st.markdown(
                                    f"""
                                    <div class="recommendation-box">
                                        Th·ªùi ƒëi·ªÉm t·ªët nh·∫•t ƒë·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi: {start_hour:02d}-{end_hour:02d}h h√¥m nay.
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )
                            elif start_is_today:
                                st.markdown(
                                    f"""
                                    <div class="recommendation-box">
                                        Th·ªùi ƒëi·ªÉm t·ªët nh·∫•t ƒë·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi: {start_hour:02d}h h√¥m nay - {end_hour:02d}h ng√†y mai.
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )
                            else:
                                st.markdown(
                                    f"""
                                    <div class="recommendation-box">
                                        Kh√¥ng c√≥ th·ªùi ƒëi·ªÉm t·ªët n√†o ƒë·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi h√¥m nay.
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )
                        else:
                            st.markdown(
                                f"""
                                <div class="recommendation-box">
                                    Kh√¥ng c√≥ th·ªùi ƒëi·ªÉm t·ªët n√†o ƒë·ªÉ ho·∫°t ƒë·ªông ngo√†i tr·ªùi h√¥m nay.
                                </div>
                                """,
                                unsafe_allow_html=True
                            )
            else:
                st.write("**AQI Hi·ªán t·∫°i**: Kh√¥ng c√≥ d·ªØ li·ªáu")

            # Nh·∫≠p s·ªë gi·ªù ƒë·ªÉ d·ª± ƒëo√°n v√† hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n
            hours_ahead = st.number_input("üïí Nh·∫≠p s·ªë gi·ªù mu·ªën d·ª± ƒëo√°n:", min_value=1, max_value=24, value=1, step=1, key="hours_input")
            if st.button("D·ª± ƒëo√°n"):
                predicted_values = predict_pollutants(exp, final, location_id, hours_ahead)
                if predicted_values is not None:
                    latest_pollutants = latest_data[latest_data['location_id'] == location_id].iloc[0].to_dict()
                    latest_pollutants = {k: v for k, v in latest_pollutants.items() if k in pollutants and pd.notna(v)}
                    for pollutant in pollutants:
                        if pollutant in predicted_values and predicted_values[pollutant] is not None and predicted_values[pollutant] > 0:
                            latest_pollutants[pollutant] = predicted_values[pollutant]
                        else:
                            latest_pollutants[pollutant] = 0
                    predicted_aqi_hour = calculate_aqi(latest_pollutants)
                    valid_pollutants = [p.upper() for p in pollutants if latest_pollutants[p] > 0]
                    if valid_pollutants:
                        pollutant_str = ", ".join(valid_pollutants)
                        category = get_aqi_category(predicted_aqi_hour) if predicted_aqi_hour is not None else "Kh√¥ng x√°c ƒë·ªãnh"
                        st.success(f"D·ª± ƒëo√°n ch·ªâ s·ªë AQI (d·ª±a tr√™n {pollutant_str}) sau {hours_ahead} gi·ªù n·ªØa: {predicted_aqi_hour} - M·ª©c ƒë·ªô: {category}")
                    else:
                        st.warning(f"Kh√¥ng c√≥ d·ªØ li·ªáu d·ª± ƒëo√°n cho b·∫•t k·ª≥ ch·ªâ s·ªë n√†o t·∫°i ƒë·ªãa ƒëi·ªÉm n√†y sau {hours_ahead} gi·ªù.")
                    if predicted_aqi_hour is not None and predicted_aqi_hour > 0:
                        classification = classify_aqi(predicted_aqi_hour)
                        st.markdown(
                            f"""
                            <div class="recommendation-box">
                                Trong {hours_ahead} gi·ªù n·ªØa:<br>
                                {classification['advice']}
                            </div>
                            """,
                            unsafe_allow_html=True
                        )

    # Tab S·ª©c kh·ªèe
    with tab2:
        st.subheader("ü©∫ D·ª± ƒëo√°n S·ª©c kh·ªèe C√° nh√¢n")
        if highlight_location != 'T·∫•t c·∫£':
            location_id = latest_data[latest_data['location_name'] == highlight_location]['location_id'].iloc[0]
            # L·∫•y gi√° tr·ªã PM2.5 tr·ª±c ti·∫øp t·ª´ c·ªôt 'pm25'
            current_pm25 = latest_data[latest_data['location_id'] == location_id]['pm25'].iloc[0] if not latest_data[latest_data['location_id'] == location_id].empty else 0

            # Input th√¥ng tin ng∆∞·ªùi d√πng
            st.write("‚ÑπÔ∏è **Nh·∫≠p th√¥ng tin c√° nh√¢n:**")
            age = st.number_input("üßç‚Äç‚ôÇÔ∏è Tu·ªïi", min_value=0, max_value=120, step=1)
            health_condition = st.selectbox("ü´Å T√¨nh tr·∫°ng s·ª©c kh·ªèe n·ªÅn", ["Kh√¥ng c√≥", "B·ªánh li√™n quan ƒë·∫øn h√¥ h·∫•p", "B·ªánh li√™n quan ƒë·∫øn tim m·∫°ch", "C·∫£ hai"])
            outdoor_time = st.number_input("üïê Th·ªùi gian ngo√†i tr·ªùi (gi·ªù)", min_value=0.0, max_value=24.0, step=0.5)
            activity_level = st.selectbox("üß≠ Ho·∫°t ƒë·ªông ngo√†i tr·ªùi", ["Ngh·ªâ ng∆°i", "V·∫≠n ƒë·ªông nh·∫π (ƒëi d·∫°o)", "V·∫≠n ƒë·ªông v·ª´a (ƒë·∫°p xe)", "V·∫≠n ƒë·ªông n·∫∑ng (ch·∫°y b·ªô)"])
            wears_mask = st.checkbox("üò∑ C√≥ ƒëeo kh·∫©u trang kh√¥ng?", value=False)

            # Th√™m n√∫t D·ª± ƒëo√°n
            if st.button("D·ª± ƒëo√°n", key="health_predict"):
                # T√≠nh Exposure Factor
                # 1. duration_factor = hours_outside
                duration_factor = outdoor_time

                # 2. activity_multiplier
                activity_mapping = {
                    "Ngh·ªâ ng∆°i": 1.0,
                    "V·∫≠n ƒë·ªông nh·∫π (ƒëi d·∫°o)": 1.2,
                    "V·∫≠n ƒë·ªông v·ª´a (ƒë·∫°p xe)": 1.5,
                    "V·∫≠n ƒë·ªông n·∫∑ng (ch·∫°y b·ªô)": 2.0
                }
                activity_multiplier = activity_mapping[activity_level]

                # 3. mask_efficiency
                mask_efficiency = 0.5 if wears_mask else 1.0

                # T·ªïng Exposure Factor
                exposure_factor = duration_factor * activity_multiplier * mask_efficiency

                # T√≠nh Sensitivity Factor
                sensitivity_factor = 1.0  # Gi√° tr·ªã c∆° b·∫£n
                # ƒêi·ªÅu ch·ªânh theo tu·ªïi
                if age < 12 or age > 65:
                    sensitivity_factor += 0.5
                # ƒêi·ªÅu ch·ªânh theo b·ªánh n·ªÅn
                health_condition_mapping = {
                    "Kh√¥ng c√≥": 0,
                    "B·ªánh li√™n quan ƒë·∫øn h√¥ h·∫•p": 0.3,
                    "B·ªánh li√™n quan ƒë·∫øn tim m·∫°ch": 0.3,
                    "C·∫£ hai": 0.6
                }
                num_conditions = health_condition_mapping[health_condition]
                sensitivity_factor += num_conditions

                # Gi√° tr·ªã Potency (h·∫±ng s·ªë)
                potency = 0.006

                # T√≠nh Risk Score: Risk Score = PM2.5 √ó Exposure Factor √ó Sensitivity Factor √ó Potency
                risk_score = current_pm25 * exposure_factor * sensitivity_factor * potency

                # ƒê√°nh gi√° Risk Score (theo ng∆∞·ª°ng m·ªõi)
                risk_description = ""
                risk_icon = ""
                if risk_score < 0.03:
                    risk_description = "An to√†n, s·ª©c kh·ªèe b√¨nh th∆∞·ªùng"
                    risk_icon = "‚úÖ"
                elif 0.03 <= risk_score <= 0.06:
                    risk_description = "H·∫°n ch·∫ø ra ngo√†i n·∫øu kh√¥ng c·∫ßn thi·∫øt"
                    risk_icon = "‚ö†Ô∏è"
                elif 0.06 < risk_score <= 0.1:
                    risk_description = "Khuy·∫øn ngh·ªã tr√°nh ra ngo√†i trong th·ªùi gian d√†i, c√¢n nh·∫Øc ·ªü trong nh√†"
                    risk_icon = "üö´"
                else:  # risk_score > 0.1
                    risk_description = "C·∫£nh b√°o nghi√™m tr·ªçng, ·ªü trong nh√† v√† t√¨m ki·∫øm t∆∞ v·∫•n b√°c sƒ©"
                    risk_icon = "üõë"

                st.markdown(
                    f"""
                    <div class="recommendation-box">
                        {risk_icon} {risk_description}
                    </div>
                    """,
                    unsafe_allow_html=True
                )
        else:
            st.write("Vui l√≤ng ch·ªçn m·ªôt ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ d·ª± ƒëo√°n s·ª©c kh·ªèe.")

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì ƒë∆∞·ªùng
st.subheader("üìâ Bi·ªÉu ƒë·ªì")
location_selected = st.selectbox('Ch·ªçn ƒë·ªãa ƒëi·ªÉm:', unique_locations)

temp_df = final[final['location_name'] == location_selected].copy()
line_df = temp_df.pivot(index='time_index', columns='parameter', values='value').reset_index()
line_df['Time'] = pd.date_range(start='2025-05-01', periods=len(line_df), freq='H')
line_df_melt = line_df.melt(id_vars=['Time'], value_vars=[col for col in line_df.columns if col != 'Time' and col != 'time_index'],
                            var_name='Parameter', value_name='Value')

value_range = line_df_melt['Value'].dropna()
if not value_range.empty:
    min_val, max_val = value_range.min(), value_range.max()
    tickvals = list(range(int(min_val), int(max_val) + 1, max(1, int((max_val - min_val) / 10))))
else:
    tickvals = [0]

fig_line = px.line(
    line_df_melt,
    x='Time',
    y='Value',
    color='Parameter',
    title=f"Air Quality Parameters at {location_selected}"
)
fig_line.update_layout(
    yaxis=dict(
        tickvals=tickvals,
        title="Gi√° tr·ªã",
        gridcolor='lightgray'
    ),
    xaxis_title="Th·ªùi gian",
    showlegend=True
)
st.plotly_chart(fig_line, use_container_width=True)